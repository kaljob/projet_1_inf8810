{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2: Hadoop (11 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions\n",
    "Nom: HOUNTONDJI Fabrice\n",
    "Code Permanent: HOUM05369902\n",
    "\n",
    "Nom: KALJOB Martial\n",
    "Code Permanent: KALM30319404"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif et Utilité de vnotre traitement MapReduce\n",
    "\n",
    "L'objectif de notre traitement est de calculer le prix moyen d'une location par lieux géographique (Montreal, etc). \n",
    "Nous afficherons les 10 villes les plus chers et les 10 villes les plus moins chere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description des étapes de notre traitement MapReduce\n",
    "- dans la partie 1 nous avons crée un fichier simplifié a partir des données que nous avons récupéré sur Airbnb\n",
    "- Creation d'un Mapper : pour chaque ligne de notre fichier d'entrée nous recuperons la ville et le montant.\n",
    "- Creation d'un Reducer : \n",
    "    - Creation d'une liste qui contiendra tous les prix des annonces de cette ville. nous ferons un traitement sur le prix (retait du symbole dollars)\n",
    "    - Creation d'un dictionnaire qui contiendra comme clé des villes et comme valeures le prix moyen des annonces dans cette ville\n",
    "    - nous avons crée un dictionnaire avec les prix ordonnés. ce qui nous à permis d'avoir les dix villes avec un prix moyen d'annonce de logement élevé et les 10 villes avec un prix d'annonce de logement le moins chers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation des étapes et test de notre traitement à l'extérieur de Hadoop\n",
    "- Voir le Mapper mapper.py\n",
    "- voir le fichier Reducer reducer.py\n",
    "Pour executer le traitement vous devez executer la commenda ci dessous\n",
    "\n",
    "```shell\n",
    "cat listings_clean.csv | python3 mapper.py | python3 reducer.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajout de nos données à HDFS et ajout de notre mapper et reducer dans un environnement Hadoop\n",
    "Nous utiliser un environnement docker pour mettre en place l'infrastructure Hadoop Streaming\n",
    "- Clone du projet \n",
    "```bash\n",
    "git clone https://github.com/arminZolfaghari/docker-hadoop.git\n",
    "```\n",
    "- Naviguer dans le repertoire docker-hadoop pour deployer l'infrastructure\n",
    "```bash\n",
    "cd docker-hadoop\n",
    "```\n",
    "- deploiement de l'infrastructure\n",
    "```bash\n",
    "docker-compose up -d\n",
    "```\n",
    "- copies des fichiers dans le namenode hadoop\n",
    "```bash\n",
    "docker cp ../mapper.py namenode:/\n",
    "docker cp ../reducer.py namenode:/\n",
    "docker cp ../listings_clean.csv namenode:/\n",
    "```\n",
    "- Connexion au cluster Hadoop Streaming\n",
    "```bash\n",
    "docker exec -it namenode bash\n",
    "```\n",
    "- Creation d'un repertoire dans HDFS\n",
    "```bash\n",
    "hadoop fs -mkdir -p /user/root\n",
    "```\n",
    "- Ajout de notre jeu de données à HDFS\n",
    "```bash\n",
    "hadoop fs -put listings_clean.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lancer le traitement avec Hadoop Streaming\n",
    "- Toujours dans notre cluster HDFS executons la commande ci-dessous\n",
    "```bash\n",
    "hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar -file mapper.py -mapper \"python3 mapper.py\" -file reducer.py -reducer \"python3 reducer.py\" -input listings_clean.csv -output resultat\n",
    "```\n",
    "\n",
    "- On peut regarder le nom du fichier produit\n",
    "```bash\n",
    "hadoop fs -ls resultat\n",
    "```\n",
    "- Visualisation d'une partie du resultat\n",
    "```bash\n",
    "hadoop dfs -tail resultat/part-00000\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
